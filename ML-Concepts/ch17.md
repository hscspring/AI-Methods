# 西瓜书概念


## 附录


- Page399: 行列式（determinant）
  
  n 阶方阵 A 的行列式（determinant）定义为：  
  $$det(A) = \sum_{\sigma \in S_n} par(\sigma) A_{1\sigma_1}A_{2\sigma_2}...A_{n\sigma_n}$$  
  其中，Sn 为所有 n 阶排列（permutation）的集合，par(σ) 的值为 -1 或 +1 取决于 σ = (σ1,σ2,...σn) 为奇排列或偶排列，即其中出现降序的次数为奇数或偶数，例如 (1,3,2) 中降序次数为 1，(3,1,2) 中降序次数为 2。对于单位阵，有 det(I) = 1。
    
  直观理解：
  - 是什么：以二维为例，表示一个区域的面积，负数则是将区域翻转，或者说定向改变。如果矩阵所代表的变换将空间压缩到更小的维度（不满秩），则行列式为 0（比如二维到一维，面积就变成了零）。列代表基向量，行代表坐标，一个 m×n 的矩阵表示 n 个基向量表示的空间映射在 m 维的坐标上。行列式是面积（二维）或体积（三维）缩放的比例。 
  - 怎么算：以二维为例，主对角线元素代表两个维度缩放的比例，其余两个元素代表两个维度的坐标区域对角线的缩放。  
  
- Page399: 迹（trace）
  
  对于 n 阶方阵 A，它的迹（trace）是主对角线上的元素之和，即：  
  $$tr(A) = \sum_{i=1}^n A_ii$$
  
- Page400: Frobenius 范数
  
  矩阵 A(m×n) 的 Frobenius 范数定义为：  
  $$\Arrowvert A \Arrowvert_F = (tr(A^TA))^{1/2} = \lgroup \sum_{i=1}^m \sum_{j=1}^n A_{ij}^2 \rgroup ^{1/2}$$  
  矩阵的 Frobenius 范数就是将矩阵张成向量后的 L2 范数，其实就是所有元素的平方和再开方。
  
- Page402: 低秩矩阵近似问题
  
  给定一个秩为 r 的矩阵 A，欲求其最优 k 秩近似矩阵 A'（k ≤ r），这样的问题称为低秩矩阵近似问题。  
  该问题可以形式化为：  
  $$min_{A' \in R^{m*n}} \ \ \Arrowvert A - A' \Arrowvert_F, \ \ \ s.t. rank(A') = k$$  
  该问题可以使用奇异值分解：对矩阵 A 进行奇异值分解后，将 Σ 矩阵（见奇异值分解）的 r-k 个最小的奇异值置零获得矩阵 Σ_k，A_k = U_k Σ_k V_k^T 就是最优解，其中 U_k 和 V_k 分别是 U 和 V 前 k 列组成的矩阵。这个结果也称为 Eckart-Young-Mirsky 定理。
  
- Page402: 奇异值分解（Singular Value Decomposition，简称 SVD）
  
  对任意矩阵 $$A \in \mathbb{R}^{m\times n}$$ 都可分解为：$$A = U\sum V^T$$，其中，$$U \in \mathbb{R}^{m\times m}$$ 是满足 $$U^TU=I$$ 的 m 阶酉矩阵（unitary matrix）；$$V \in \mathbb{R}^{n \times n}$$ 是满足 $$V^TV=I$$ 的 n 阶酉矩阵；$$\sum \in \mathbb{R}^{m \times n}$$ 是 m×n 的矩阵，其中 $$(\sum)_{ii} = \sigma_i$$ 且其他位置的元素均为 0，$$\sigma_i$$ 为非负实数且满足 $$\sigma_1 \ge \sigma_2 \ge ... \ge 0$$。
  
- Page403: 拉格朗日乘子法（Lagrange multipliers）
  
  拉格朗日乘子法是一种寻找多元函数在一组约束下的极值的方法。通过引入拉格朗日乘子，可将有 d 个变量与 k 个约束条件的最优化问题转化为具有 d+k 个变量的无约束优化问题求解。有等式约束和不等式约束两种。  
  以等式约束的优化问题为例。假定 x 为 d 维向量，要求 x 的某个取值 x\* 使目标函数 f(x) 最小且同时满足 g(x)=0 的约束。从几何角度看该问题的目标是在由方程 g(x)=0 确定的 d-1 维曲面上寻找能使目标函数 f(x) 最小化的点。此时很容易得出在最优点目标函数与约束函数相切（即目标函数在该点的梯度正交于约束曲面）。由此可知，在最优点，梯度 $$\nabla g(x), \nabla f(x)$$ 方向相同或相反：，即存在 λ ≠ 0 使得 $$\nabla f(x^*) + \lambda \nabla g(x^*) = 0$$，λ 称为拉格朗日乘子，定义拉格朗日函数为：$$L(x, \lambda) = f(x) + \lambda g(x)$$。
  
- Page405: 对偶函数（dual function）
  
  将优化问题的约束推广到多个：具有 m 个等式约束和 n 个不等式约束，且可行域 $$\mathbb{D} \subset \mathbb{R}^d $$ 非空的优化问题：  
  $$min_x f(x) \ \ s.t.\ \ h_i(x) = 0\ (i=1,...m);\ g_j(x) \le 0\ (j=1,...n)$$  
  该问题为优化问题的主问题（primal problem），相应的拉格朗日函数为：  
  $$L(x,\lambda,\mu) = f(x) + \sum_{i=1}^m \lambda_i h_i(x) + \sum_{j=1}^n \mu_j g_j(x)$$，  
  其对偶函数定义为：  
  $$\Gamma(\lambda, \mu) = \inf_{x\in D} L (x, \lambda, \mu) = \inf_{x\in D} \lgroup f(x) + \sum_{i=1}^m \lambda_i h_i(x) + \sum_{j=1}^n \mu_j g_j(x)\rgroup$$。  
  对偶函数给出了主问题的最优值下界，因为若 x\* 为主问题可行域的点，对任意 $$\mu \succeq 0, \lambda$$，都有 $$\sum_{i=1}^m \lambda_i h_i(x) + \sum_{j=1}^n \mu_j g_j(x) \le 0$$，进而有 $$\Gamma(\lambda,\mu) \le L(x^*, \lambda, \mu) \le f(x^*)$$。
  
- Page406: 二次规划（Quadratic Programming，简称 QP）
  
  一类典型的优化问题，包括凸二次优化和非凸二次优化。目标函数是变量的二次函数，约束条件是变量的线性不等式。假定变量个数为 d，约束条件个数为 m，标准的二次规划问题形如：  
  $$\min_x \ \  \frac{1}{2} x^TQx + c^Tx, \ \ s.t. Ax \le b$$  
  其中，x 为 d 维向量， Q ∈ R 为实对称矩阵，A ∈ R 为实矩阵，b ∈ R 和 c ∈ R 为实向量，Ax ≤ b 的每一行对应一个约束。
  
- Page407: 半正定规划（Seme-Definite Programming，简称 SDP）
  
  是一类凸优化问题，其中的变量可组织成半正定对称矩阵形式，且优化问题的目标函数和约束都是这些变量的线性函数。  
  给定 d×d 的对称矩阵 **X, C**，$$C·X = \sum_{i=1}^d\sum_{j=1}^dC_{ij}X_{ij}$$，  
  若 Ai(i=1,...,m) 也是 d×d 的对称矩阵，bi(i=1,2,...,m) 为 m 个实数，则半正定规划问题形如：  
  $$min_X C · X; \ \ s.t. \ A_i \cdot X = b_i; \ \ i = 1,2,...,m, X \succeq 0$$
  
  
- Page409: 伯努利分布（Bernoulli distribution）
  
  关于布尔变量 x ∈ {0,1} 的概率分布，其连续参数 μ ∈ \[0,1\] 表示变量 x=1 的概率。  
  $$P(x|\mu) = Bern(x|\mu) = \mu^x(1-\mu)^{(1-x)}$$  
  $$\mathbb{E}[x] = \mu; var[x] = \mu(1-\mu)$$
  
- Page409: 均匀分布（uniform distribution）
  
  关于定义在区间 `[a,b](a<b)` 上连续变量的简单概率分布。  
  $$p(x|a,b) = U(x|a,b) = \frac{1}{b-a}$$  
  $$\mathbb{E}[x] = \frac{a+b}{2}; var[x] = \frac{(b-a)^2}{12}$$
  
- Page410: 多项分布（multinominal distribution）
  
  将伯努利分布由单变量扩展为 d 维，并在此基础上扩展二项分布就得到多项分布，它描述了在 N 次独立实验中有 mi 次 xi=1 的概率。  
  $$P(m_1,m_2,...,m_d|N,\mu) = Mult(m_1,m_2,...,m_d|N,\mu) = \frac{N!}{m_1!m_2!...m_d!} \prod_{i=1}^d \mu_i^{m_i}$$  
  $$\mathbb{E}[m_i] = N\mu_i; \ var[m_i] = N\mu_i(1-\mu_i); \ cov[m_j,m_i] = -N\mu_j\mu_i$$
  
- Page410: 二项分布（binomial distribution）
  
  描述 N 次是独立的伯努利实验中有 m 次成功（x=1）的概率。  
  $$P(m|N,\mu) = Bin(m|N,\mu) = {N \choose m} \mu^m (1-\mu)^{N-m}$$
  
- Page411: 贝塔分布（Beta distribution）
  
  关于连续变量 μ ∈ \[0,1\] 的概率分布，由两个参数 a>0, b>0 确定：  
  $$p(\mu|a,b) = Beta(\mu|a,b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \mu^{a-1} (1-\mu)^{b-1} = \frac{1}{B(a,b)} \mu^{a-1}(1-\mu)^{b-1}$$  
  $$\mathbb{E}[\mu] = \frac{a}{a+b}; \ var[\mu] = \frac{ab}{(a+b)^2(a+b+a)}; \ \Gamma(a) = \int_{0}^{+\infty}t^{a-1}e^{-t}dt$$  
  当 a=b=1 时，贝塔分布退化为均匀分布。
  
- Page412: 狄利克雷分布（Dirichlet distribution）
  
  关于一组 d 个连续变量 μi ∈ \[0,1\] 的概率分布，$$\sum_{i=1}^d \mu_i = 1$$。令 $$\mu = (\mu_1,...,\mu_d)$$，参数 $$\alpha = (\alpha_1,...,\alpha_d), \ \alpha_i>0, \hat{\alpha} = \sum_{i=1}^d \alpha_i$$  
  $$p(\mu|\alpha) = Dir(\mu|\alpha) = \frac{\Gamma(\hat{\alpha})}{\Gamma(\alpha_1)...\Gamma(\alpha_i）} \prod_{i=1}^d \mu_i^{(\alpha_i-1)}$$  
  $$\mathbb{E}[\mu_i] = \frac{\alpha_i}{\hat{\alpha}}, \ var[\mu_i] = \frac{\alpha_i(\hat{\alpha}-\alpha_i)}{\hat{\alpha}^2(\hat{\alpha}+1)}, \ cov[\mu_j,\mu_i] = \frac{\alpha_j\alpha_i}{\hat{\alpha}^2(\hat{\alpha}+1)}$$  
  当 d=2 时，狄利克雷分布退化为贝塔分布。
  
- Page412: 高斯分布（Gaussian distribution）
  
  亦称正态分布（normal distribution），是应用最广泛的连续概率分布。  
  对于单变量 x ∈ (-∞, +∞)，高斯分布的参数为均值 μ ∈ (-∞, +∞) 和 方差 σ^2 > 0。  
  $$p(x|\mu,\sigma^2) = \mathcal{N}(x|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp \{ -\frac{(x-\mu)^2}{2\sigma^2} \}$$  
  $$\mathbb{E}=\mu, \ var[x]=\sigma^2$$  
  对于 d 维向量 **x**，多元高斯分布的参数为 d 维均值向量 **μ** 和 d×d 的对称正定协方差矩阵 **Σ**。  
  $$p(x|\mu,\sum) = \mathcal{N}(x|\mu,\sum) = \frac{1}{\sqrt{2\pi^d \det(\sum)}} \exp \{ -\frac{1}{2}(x-\mu)^T {\sum}^{-1}(x-\mu) \}$$  
  $$\mathbb{E}=\mu, \ var[x]=\sum$$
  
- Page412: 正态分布（normal distribution）
  
  同高斯分布。
  
- Page413: 共轭分布（conjugate distribution）
  
  假设变量 x 服从分布 P(x|Θ)，其中 Θ 为参数，X={x1,x2,...,xm} 为变量 x 的观测样本，假设参数 Θ 服从先验分布 ∏(Θ)。  
  若由先验分布 ∏(Θ) 和抽样分布 P(X|Θ) 决定的后验分布 F(Θ|X) 与 ∏(Θ) 是同种类型的分布，则称先验分布 ∏(Θ) 为分布 P(X|Θ) 或 P(x|Θ) 的共轭分布。
  
- Page414: 相对熵（relative entropy）
  
  亦称 KL 散度或信息散度，可用于度量两个概率分布之间的差异。给定两个概率分布 P 和 Q，二者之间的相对熵定义为：  
  $$KL(P||Q) = \int_{-\infty}^{+\infty} p(x)\log\frac{p(x)}{q(x)}dx$$  
  其中 p(x) 和 q(x) 分别为 P 和 Q 的概率密度函数。  
  通俗地说，用分布 Q 的最佳信息传递方式来传达分布 P，比用分布 P 自己的最佳信息方式传达平均多耗费的信息长度为 KL 散度。
  
- Page414: 信息散度（information divergence）
  
  同相对熵。
  
- Page415: 交叉熵（cross entropy）
  
  KL 散度展开可得：  
  $$KL(P||Q) = \int_{-\infty}^{+\infty} p(x)\log p(x)dx - \int_{-\infty}^{+\infty} p(x)\log q(x)dx = -H(P) + H(P,Q)$$  
  其中 H(P) 为熵，H(P,Q) 为 P 和 Q 的交叉熵。
  通俗地说，用分布 Q 的最佳信息传递方式传达分布 P 中随机抽选的一个事件，所需的平均信息长度为交叉熵。
  
- Page415: 熵（entropy）
  
  熵是对整个事件信息量的量化，传达信息所需的最优平均信息长度为香农熵。  
  $$H(P) = \sum_xP(x)\log\frac{1}{P(x)}$$


---

附：一些不错的学习资料

-  奇异值分解
	- [奇异值分解 SVD 的数学解释 - CSDN 博客](https://blog.csdn.net/u010099080/article/details/68060274)
	- [(3 条消息) 奇异值的物理意义是什么？ - 知乎](https://www.zhihu.com/question/22237507)
	- [机器学习中的数学 (5)- 强大的矩阵奇异值分解 (SVD) 及其应用 - LeftNotEasy - 博客园](http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/1939687.html)
	- [奇异值分解 (SVD) 原理详解及推导 - CSDN 博客](https://blog.csdn.net/zhongkejingwang/article/details/43053513)

- 拉格朗日乘子法
	- [(3 条消息) 拉格朗日乘子法如何理解？ - 知乎](https://www.zhihu.com/question/38586401)
	- [【整理】深入理解拉格朗日乘子法（Lagrange Multiplier) 和 KKT 条件 - mo\_wang - 博客园](http://www.cnblogs.com/mo-wang/p/4775548.html)
	- [An Introduction to Lagrange Multipliers](http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html)

- 梯度
	- [文章](https://www.matongxue.com/madocs/222.html#/madoc)
	- [为什么梯度反方向是函数值局部下降最快的方向？](https://zhuanlan.zhihu.com/p/24913912)
	- [梯度 - YouTube](https://www.youtube.com/watch?v=npkl19rcpdY)

- 正定矩阵和半正定矩阵
	- [正定矩阵与半正定矩阵定义性质与理解 - CSDN 博客](https://blog.csdn.net/asd136912/article/details/79146151)

- 贝塔分布
    - [带你理解 beta 分布 - CSDN 博客](https://blog.csdn.net/a358463121/article/details/52562940)

- 狄利克雷分布
	- [(2 条消息) 什么是狄利克雷分布？狄利克雷过程又是什么？ - 知乎](https://www.zhihu.com/question/26751755)
	- [机器学习的数学基础（1）--Dirichlet 分布 - CSDN 博客](https://blog.csdn.net/jwh_bupt/article/details/8841644)
	- [科学网—再谈分布之分布（dirichlet 分布）- 贝叶斯分析之 2 - 张天蓉的博文](http://blog.sciencenet.cn/blog-677221-1051014.html)
	- [通俗理解 Dirichlet 分布及其实践 | A Notebook](https://xijunlee.github.io/2017/09/09/Dirichlet%E5%88%86%E5%B8%83%E4%B8%8EBeta%E5%88%86%E5%B8%83/)
	- [Dirichlet Distribution（狄利克雷分布）与 Dirichlet Process（狄利克雷过程） | 数据学习者官方网站 (Datalearner)](https://www.datalearner.com/blog/1051459673766843)
	- [LDA数学八卦](http://emma.memect.com/t/9756da9a47744de993d8df13a26e04e38286c9bc1c5a0d2b259c4564c6613298/LDA)

- 熵、相对熵、交叉熵
	- [Shannon entropy in the context of machine learning and AI](https://medium.com/swlh/shannon-entropy-in-the-context-of-machine-learning-and-ai-24aee2709e32)
	- [如何理解KL散度的不对称性 | 机器之心](https://www.jiqizhixin.com/articles/0224)
	- [【 深度学习 】熵，交叉熵，KL 散度 Entropy, Cross-Entropy and KL-Divergence](https://www.bilibili.com/video/av19193502?from=search&seid=9145887951572377038)









